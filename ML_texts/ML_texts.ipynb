{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed944c3e",
   "metadata": {},
   "source": [
    "# Проект для \"Викишоп\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7edf6a",
   "metadata": {},
   "source": [
    "Обучение модели, способной классифицировать позитивные и негативные комментарии на основе набора с разметкой о токсичности пользовательских правок описаний товаров в интернет-магазине \"Викишоп\" с целью выявления и предотвращения токсичных комментариев.\n",
    "\n",
    "Необходимо добиться значения метрики качества `F1` не меньше `0.75`.\n",
    "\n",
    "**Ход исследования:**\n",
    "* Загрузка данных и первичное ознакомление с ними;\n",
    "\n",
    "* Подготовка данных к работе:\n",
    "    \n",
    "    * Очистка и лемматизация текста;\n",
    "    \n",
    "    * Разделение данных на выборки;\n",
    "    \n",
    "    * Выделение признаков из текстовых данных;\n",
    "\n",
    "* Обучение разных моделей:\n",
    "\n",
    "    * Модель логистической регрессии `LogisticRegression`;\n",
    "    \n",
    "    * Модель градиентного бустинга `CatBoostClassifier`;\n",
    "    \n",
    "    * Модель градиентного бустинга `XGBClassifier`;\n",
    "    \n",
    "    * Модель градиентного бустинга `LGBMClassifier`;\n",
    "    \n",
    "* Анализ скорости работы и качества моделей;\n",
    "\n",
    "* Итоги исследования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158a94b",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f5d9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.6.1-py3-none-win_amd64.whl (125.4 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a38021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.6-cp39-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: plotly in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d3476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\y_gri\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779df454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение необходимых библиотек\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cad0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\y_gri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "# для nltk.pos_tag()\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# для nltk.word_tokenize()\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a3e5a",
   "metadata": {},
   "source": [
    "Прочитаем данные из файла `/datasets/toxic_comments.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fa28bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# локально\n",
    "#df = pd.read_csv('toxic_comments.csv')\n",
    "# ЯП\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e61b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49981732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22b6895f708>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x='toxic', data=df, palette='pastel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e7d05",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Итак, у нас есть 159 тысяч объектов, содержащих пока что не обработанные англоязычные комментарии и соответсвующие им значения целевого признака `toxic`. Заметим, что негативных комментариев в датафрейме гораздо меньше, чем нейтральных. Чтобы подготовить данные стобца `text` к обучению на них моделей, необходимо упростить его, а затем извлечь из него признаки для обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699bf6c",
   "metadata": {},
   "source": [
    "## Подготовка данных к работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12886d64",
   "metadata": {},
   "source": [
    "Сначала очистим комментарии  из столбца `text` от ненужных символов, оставив только слова и пробелы, а затем лемматизируем их. Лемматизацию проведем используя лемматизатор `Wordnet` из библиотеки `nltk`. Для этого создадим соответсвующие функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abe92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция определения POS-тегов (указывает на часть речи в данном контексте) для каждого слова\n",
    "\n",
    "def get_wordnet_pos(text):\n",
    "    tag = nltk.pos_tag([text])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9e5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55dce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция лемматизации текста с помощью wordnet\n",
    "\n",
    "def lemmatize_wordnet(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemm_list = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words])\n",
    "    return lemm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20b568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция очистки текста от лишних символов с использованием регулярных выражений \n",
    "# и приведение к нижнему регистру\n",
    "\n",
    "def clear_text(text):\n",
    "    result = \" \".join(re.sub(r\"[^a-zA-Z' ]\", \" \", text).lower().split())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13019cae",
   "metadata": {},
   "source": [
    "Применим функции ко всем имеющимся данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6fd833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 54min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text_lemm'] = df['text'].apply(lambda text: lemmatize_wordnet(clear_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15060787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not try to edit war it 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           text_lemm  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d'aww he match this background colour i 'm see...  \n",
       "2  hey man i 'm really not try to edit war it 's ...  \n",
       "3  more i ca n't make any real suggestion on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7cffb8",
   "metadata": {},
   "source": [
    "Так как преобразование занимает довольно долгое время, сразу сохраним полученные результаты в новой таблице, чтобы в дальнейшем не повторять времязатратный процесс лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b2f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('toxic_comments_lemm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7841e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments_lemm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f396ba",
   "metadata": {},
   "source": [
    "Теперь разделим датасет на обучающую и тестовую выборки в соотношении 3:1. В качестве признаков оставим только целевой (`toxic`) и лемматизированные тексты (`text_lemm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d64e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = df['text_lemm'], df['toxic']\n",
    "\n",
    "# выделение обучающей и тестовой выборок размером 75% и 25%\n",
    "train_ft, test_ft, train_tg, test_tg = train_test_split(features, target, test_size=0.25, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d42feef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = train_ft.fillna('')\n",
    "test_ft = test_ft.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865c2fa",
   "metadata": {},
   "source": [
    "На всякий случай проверим размеры выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba04ad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объем обучающей выборки: 119678 объектов\n",
      "Объем тестовой выборки: 39893 объектов\n"
     ]
    }
   ],
   "source": [
    "print(f'Объем обучающей выборки: {train_ft.shape[0]} объектов')\n",
    "print(f'Объем тестовой выборки: {test_ft.shape[0]} объектов')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e5bf8",
   "metadata": {},
   "source": [
    "Ранее был замечен сильный дисбаланс классов. Сделаем балансировку используя технику увеличения выборки `upsampling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd60f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(ft, tg, repeat):\n",
    "    ft_zeros = ft[tg == 0]\n",
    "    ft_ones = ft[tg == 1]\n",
    "    tg_zeros = tg[tg == 0]    \n",
    "    tg_ones = tg[tg == 1]    \n",
    "    \n",
    "    ft_upsampled = pd.concat(\n",
    "        [ft_zeros] + [ft_ones] * repeat)    \n",
    "    tg_upsampled = pd.concat(\n",
    "        [tg_zeros] + [tg_ones] * repeat)    \n",
    "    ft_upsampled, tg_upsampled = shuffle(        \n",
    "        ft_upsampled, tg_upsampled, random_state=111) \n",
    "    \n",
    "    return ft_upsampled, tg_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft, train_tg = upsample(train_ft, train_tg, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ffb402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.594815\n",
      "1    0.405185\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.899155\n",
       "1    0.100845\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_tg.value_counts(normalize=True))\n",
    "test_tg.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e530e62",
   "metadata": {},
   "source": [
    "Теперь займемся выделением признаков. Для этого создадим корпуса текстов для обучающей и тестовой выборок и переведем лемматизированные тексты в векторный формат с помощью мешка слов и очистим их от стоп-слов (не несущих смысловой нагрузки). После чего с помощью расчета `TF-IDF` проведем оценку важности каждого из слов в корпусах текстов.\n",
    "\n",
    "Однако так как при обучении моделей будем подбирать гиперпараметры с помощью кросс-валидации, обучать векторизатор будем не на всей выборке заранее, а во время кросс-валидации, чтобы избежать возможного переобучения.\n",
    "\n",
    "Пока что загрузим словарь английских стоп-слов для векторизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db659be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка словаря английских стоп-слов\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e1a53",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "На этапе предобработки данных произошли следующие изменения:\n",
    "\n",
    "* Тексты были очищены от ненужных символов с помощью регулярных выражений и лемматизированы;\n",
    "* Данные разделены на обучающую и тестовую выборки в соотношении 75% и 25%;\n",
    "* Данные были сбалансированы с помощью техники увеличения выборки. \n",
    "* Лемматизированные тексты приведены в векторный вид и с помощью мешка слов и расчета TF-IDF из них созданы признаки для обучения моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e4ef5",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6542ed9",
   "metadata": {},
   "source": [
    "Оценку качества моделей будем проводить с помощью метрики `F1-score`.\n",
    "\n",
    "Проверим в действии следующие модели:\n",
    "\n",
    " * Модель логистической регрессии `LogisticRegression`;\n",
    "     \n",
    " * Модель градиентного бустинга `XGBClassifier`;\n",
    "    \n",
    " * Модель градиентного бустинга `CatBoostClassifier`;\n",
    "    \n",
    " * Модель градиентного бустинга `LGBMClassifier`;\n",
    "    \n",
    " * Модель классификации текстов `BERT`.\n",
    " \n",
    "Подберем для них наилучшие гиперпараметры с помощью кросс-валидации на обучающей выбрке и проверим качество их предсказаний с помощью метрики `F1` на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b99cc",
   "metadata": {},
   "source": [
    "Так как процедура обучения и предсказания для всех моделей будет примерно одинакова, создадим отдельные функции, отвечающие за это и за расчет времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e06046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция обучения моделей и расчета времени\n",
    "\n",
    "def fit_model(model_name, classifier, train_ft, train_tg):\n",
    "    time0 = time.time()\n",
    "    model = classifier\n",
    "    model.fit(train_ft, train_tg)\n",
    "    time_fit = round(time.time() - time0, 4)\n",
    "    \n",
    "    print(f'Время обучения модели {model_name}: {time_fit} секунд')\n",
    "    \n",
    "    return model, time_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da2309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция предсказания модели для тестовой выборки и проверки метрики f1\n",
    "\n",
    "def pred_model(model_name, model, test_ft, test_tg):\n",
    "    predictions = model.predict(test_ft)\n",
    "    f1 = f1_score(predictions, test_tg).round(4)\n",
    "    \n",
    "    print(f'F1-score для модели {model_name} на тестовой выборке: {f1}')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1938d05",
   "metadata": {},
   "source": [
    "Приступим к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44ef7f",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b1299",
   "metadata": {},
   "source": [
    "Начнем с модели логистической регрессии. Выставим гиперпараметры для кросс-валидации и посмотрим на результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4a56fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=25, class_weight='balanced', n_jobs=-1,\n",
       "                                    random_state=111))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model__C': 25}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9665141322564995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13 s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('model', LogisticRegression(n_jobs=-1, class_weight='balanced', solver='lbfgs', random_state=111))\n",
    "])\n",
    "\n",
    "params = {'model__C': [0.1, 0.5, 1, 5, 10, 25]}\n",
    "\n",
    "clf = GridSearchCV(pipe_lr, param_grid=params, scoring='f1', cv=3, n_jobs=-1)\n",
    "clf.fit(train_ft, train_tg)\n",
    "\n",
    "display(clf.best_estimator_, clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ec68a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели LogisticRegression: 13.5636 секунд\n"
     ]
    }
   ],
   "source": [
    "# обучение модели логистической регрессии с выбранными гиперпараметрами на трейне и расчет времени\n",
    "\n",
    "model_logreg, time_logreg = fit_model(\"LogisticRegression\", clf.best_estimator_, train_ft, train_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7069d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для модели LogisticRegression на тестовой выборке: 0.7416\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для тестовой выборки, расчет метрики качества\n",
    "\n",
    "f1_logreg = pred_model('LogisticRegression', model_logreg, test_ft, test_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df93128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'model__C': 25}</td>\n",
       "      <td>13.5636 sec</td>\n",
       "      <td>0.7416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель         Параметры Время обучения  F1-score\n",
       "0  LogisticRegression  {'model__C': 25}    13.5636 sec    0.7416"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод результатов обучения модели логистической регрессии\n",
    "\n",
    "result = []\n",
    "\n",
    "result.append({'Модель' : 'LogisticRegression', \n",
    "              'Параметры': clf.best_params_, \n",
    "              'Время обучения': f'{time_logreg} sec',  \n",
    "              'F1-score': f1_logreg})\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a4ca0",
   "metadata": {},
   "source": [
    "### Градиентный бустинг XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d57eb",
   "metadata": {},
   "source": [
    "Рассмотрим следующую модель: модель экстремального градиентного бустинга `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6e3621b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                               co...\n",
       "                               gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "                               importance_type=None, interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=8, max_leaves=0, min_child_weight=1,\n",
       "                               missing=nan, monotone_constraints='()',\n",
       "                               n_estimators=200, n_jobs=-1, num_parallel_tree=1,\n",
       "                               predictor='auto', random_state=111, reg_alpha=0,\n",
       "                               reg_lambda=1, ...))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 8, 'model__n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9217520504340331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 38s\n",
      "Wall time: 38min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('model', XGBClassifier(n_jobs=-1, booster='gbtree', random_state=111))\n",
    "])\n",
    "\n",
    "params = {'model__max_depth': [4, 6, 8], \n",
    "         'model__n_estimators': [50, 100, 200]}\n",
    "\n",
    "clf = GridSearchCV(pipe_xgb, param_grid=params, scoring='f1', cv=3, n_jobs=-1)\n",
    "clf.fit(train_ft, train_tg)\n",
    "\n",
    "display(clf.best_estimator_, clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a8e1526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели XGBClassifier: 224.1305 секунд\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели XGB c выбранными гиперпарметрами на тренировоной выборке и расчет времени\n",
    "\n",
    "model_xgb, time_xgb = fit_model('XGBClassifier', clf.best_estimator_, train_ft, train_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1a8467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для модели XGBClassifier на тестовой выборке: 0.7742\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для тестовой выборки, расчет метрики качества\n",
    "\n",
    "f1_xgb = pred_model('XGBClassifier', model_xgb, test_ft, test_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f102756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'model__C': 25}</td>\n",
       "      <td>13.5636 sec</td>\n",
       "      <td>0.7416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'model__max_depth': 8, 'model__n_estimators':...</td>\n",
       "      <td>224.1305 sec</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель                                          Параметры  \\\n",
       "0  LogisticRegression                                   {'model__C': 25}   \n",
       "1       XGBClassifier  {'model__max_depth': 8, 'model__n_estimators':...   \n",
       "\n",
       "  Время обучения  F1-score  \n",
       "0    13.5636 sec    0.7416  \n",
       "1   224.1305 sec    0.7742  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод результатов обучения модели XGB\n",
    "\n",
    "result.append({'Модель' : 'XGBClassifier', \n",
    "              'Параметры': clf.best_params_, \n",
    "              'Время обучения': f'{time_xgb} sec',  \n",
    "              'F1-score': f1_xgb})\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e0c92",
   "metadata": {},
   "source": [
    "### Градиентный бустинг CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18e8a8",
   "metadata": {},
   "source": [
    "Обучим модель градиентного бустинга `CatBoost`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb19c615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x0000020E9BFCB430>)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model__iterations': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 17s\n",
      "Wall time: 9min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('model', CatBoostClassifier(verbose=0, random_state=111))\n",
    "])\n",
    "\n",
    "params = {'model__iterations': [100, 200, 500]}\n",
    "\n",
    "clf = GridSearchCV(pipe_cat, param_grid=params, scoring='f1', cv=3, n_jobs=-1)\n",
    "clf.fit(train_ft, train_tg)\n",
    "\n",
    "display(clf.best_estimator_, clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df12b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели CatBoostClassifier: 215.7639 секунд\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели CatBoostClassifier c выбранными гиперпарметрами на тренировоной выборке и расчет времени\n",
    "\n",
    "model_cat, time_cat = fit_model('CatBoostClassifier', clf.best_estimator_, train_ft, train_tg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ccbe2",
   "metadata": {},
   "source": [
    "И узнаем качество нашей модели на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7741281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для модели CatBoostClassifier на тестовой выборке: 0.7512\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для тестовой выборки, расчет метрики качества\n",
    "\n",
    "f1_cat = pred_model('CatBoostClassifier', model_cat, test_ft, test_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6079b485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'model__C': 25}</td>\n",
       "      <td>13.5636 sec</td>\n",
       "      <td>0.7416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'model__max_depth': 8, 'model__n_estimators':...</td>\n",
       "      <td>224.1305 sec</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'model__iterations': 100}</td>\n",
       "      <td>215.7639 sec</td>\n",
       "      <td>0.7512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель                                          Параметры  \\\n",
       "0  LogisticRegression                                   {'model__C': 25}   \n",
       "1       XGBClassifier  {'model__max_depth': 8, 'model__n_estimators':...   \n",
       "2  CatBoostClassifier                         {'model__iterations': 100}   \n",
       "\n",
       "  Время обучения  F1-score  \n",
       "0    13.5636 sec    0.7416  \n",
       "1   224.1305 sec    0.7742  \n",
       "2   215.7639 sec    0.7512  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод результатов обучения модели CatBoostClassifier\n",
    "\n",
    "result.append({'Модель' : 'CatBoostClassifier', \n",
    "              'Параметры': clf.best_params_, \n",
    "              'Время обучения': f'{time_cat} sec',  \n",
    "              'F1-score': f1_cat})\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac59683",
   "metadata": {},
   "source": [
    "### Градиентный бустинг LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9a375",
   "metadata": {},
   "source": [
    "Следующая модель: модель градиентого бустинга `LightGBM`. С ней работаем все по той же схеме. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d2efe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('model',\n",
       "                 LGBMClassifier(max_depth=8, n_estimators=200,\n",
       "                                random_state=111))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.1,\n",
       " 'model__max_depth': 8,\n",
       " 'model__n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8664075618087943"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 58s\n",
      "Wall time: 20min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('model', LGBMClassifier(random_state=111))\n",
    "])\n",
    "\n",
    "params = {'model__max_depth': [4, 6, 8], \n",
    "         'model__n_estimators': [50, 100, 200], \n",
    "         'model__learning_rate': [0.1, 0.03]}\n",
    "\n",
    "clf = GridSearchCV(pipe_lgbm, param_grid=params, scoring='f1', cv=3, n_jobs=-1)\n",
    "clf.fit(train_ft, train_tg)\n",
    "\n",
    "display(clf.best_estimator_, clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dfb2742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели LGBMClassifier: 63.7614 секунд\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели LightGBM c выбранными гиперпарметрами на тренировоной выборке и расчет времени\n",
    "\n",
    "model_lgbm, time_lgbm = fit_model('LGBMClassifier', clf.best_estimator_, train_ft, train_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f17a6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для модели LGBMClassifier на тестовой выборке: 0.758\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для тестовой выборки, расчет метрики качества\n",
    "\n",
    "f1_lgbm = pred_model('LGBMClassifier', model_lgbm, test_ft, test_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54d5128a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'model__C': 25}</td>\n",
       "      <td>13.5636 sec</td>\n",
       "      <td>0.7416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'model__max_depth': 8, 'model__n_estimators':...</td>\n",
       "      <td>224.1305 sec</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'model__iterations': 100}</td>\n",
       "      <td>215.7639 sec</td>\n",
       "      <td>0.7512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "      <td>63.7614 sec</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель                                          Параметры  \\\n",
       "0  LogisticRegression                                   {'model__C': 25}   \n",
       "1       XGBClassifier  {'model__max_depth': 8, 'model__n_estimators':...   \n",
       "2  CatBoostClassifier                         {'model__iterations': 100}   \n",
       "3      LGBMClassifier  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
       "\n",
       "  Время обучения  F1-score  \n",
       "0    13.5636 sec    0.7416  \n",
       "1   224.1305 sec    0.7742  \n",
       "2   215.7639 sec    0.7512  \n",
       "3    63.7614 sec    0.7580  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод результатов обучения модели LightGBM\n",
    "\n",
    "result.append({'Модель' : 'LGBMClassifier', \n",
    "              'Параметры': clf.best_params_, \n",
    "              'Время обучения': f'{time_lgbm} sec',  \n",
    "              'F1-score': f1_lgbm})\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edde67",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2743c1",
   "metadata": {},
   "source": [
    "Соберем все полученные результаты воедино:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f5c73a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>13.5636</td>\n",
       "      <td>0.7416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>224.1305</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>215.7639</td>\n",
       "      <td>0.7512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>63.7614</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель  Время обучения  F1-score\n",
       "0  LogisticRegression         13.5636    0.7416\n",
       "1       XGBClassifier        224.1305    0.7742\n",
       "2  CatBoostClassifier        215.7639    0.7512\n",
       "3      LGBMClassifier         63.7614    0.7580"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Модель': ['LogisticRegression', 'XGBClassifier', 'CatBoostClassifier', 'LGBMClassifier'], \n",
    "             'Время обучения': [time_logreg, time_xgb, time_cat, time_lgbm], \n",
    "             'F1-score': [f1_logreg, f1_xgb, f1_cat, f1_lgbm]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a99831",
   "metadata": {},
   "source": [
    "## Итоги исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977324a6",
   "metadata": {},
   "source": [
    "* Были опробованы 4 модели: логистическая регрессия, XGBoost, CatBoost и LightGBM, а качество их предсказаний оценикалось метрикой f1-score.\n",
    "* Наиболее быстрой по времени обучения оказалась модель логистической регрессии, но ее F1-score не достигает необходимого порога. \n",
    "* Наиболее высокого результата метрики f1 удалось достичь модели `XGBClassifier`, однако по времени обучения она стала самой медленной из всех использованных моделей обучения.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
